
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Youwei Zhuo">
      
      
        <link rel="canonical" href="https://review.youwei.xyz/software/algorithm/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../pl/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Algorithms - New Lemonade Review</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JXHKVQ8LKS"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JXHKVQ8LKS",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JXHKVQ8LKS",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#algorithms-theory-and-formal-methods" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="New Lemonade Review" class="md-header__button md-logo" aria-label="New Lemonade Review" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M368 80c-3.2 0-6.2.4-8.9 1.3C340 86.8 313 92 284.8 84.6c-57.4-14.9-124.6 7.4-174.7 57.5S37.7 259.4 52.6 316.8c7.3 28.2 2.2 55.2-3.3 74.3-.8 2.8-1.3 5.8-1.3 8.9 0 17.7 14.3 32 32 32 3.2 0 6.2-.4 8.9-1.3 19.1-5.5 46.1-10.7 74.3-3.3 57.4 14.9 124.6-7.4 174.7-57.5s72.4-117.3 57.5-174.7c-7.3-28.2-2.2-55.2 3.3-74.3.8-2.8 1.3-5.8 1.3-8.9 0-17.7-14.3-32-32-32m0-48c44.2 0 80 35.8 80 80 0 7.7-1.1 15.2-3.1 22.3-4.6 15.8-7.1 32.9-3 48.9 20.1 77.6-10.9 161.5-70 220.7s-143.1 90.2-220.7 70c-16-4.1-33-1.6-48.9 3-7.1 2-14.6 3.1-22.3 3.1-44.2 0-80-35.8-80-80 0-7.7 1.1-15.2 3.1-22.3 4.6-15.8 7.1-32.9 3-48.9-20.1-77.6 10.9-161.5 70-220.7s143.2-90.1 220.7-70c16 4.1 33 1.6 48.9-3 7.1-2 14.6-3.1 22.3-3.1M246.7 167c-52 15.2-96.5 59.7-111.7 111.7-3.7 12.7-17.1 20-29.8 16.3s-20-17-16.2-29.7c19.8-67.7 76.6-124.5 144.3-144.3 12.7-3.7 26.1 3.6 29.8 16.3s-3.6 26.1-16.3 29.8z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            New Lemonade Review
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Algorithms
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/pku-lemonade/review" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pku-lemonade/review
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="New Lemonade Review" class="md-nav__button md-logo" aria-label="New Lemonade Review" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M368 80c-3.2 0-6.2.4-8.9 1.3C340 86.8 313 92 284.8 84.6c-57.4-14.9-124.6 7.4-174.7 57.5S37.7 259.4 52.6 316.8c7.3 28.2 2.2 55.2-3.3 74.3-.8 2.8-1.3 5.8-1.3 8.9 0 17.7 14.3 32 32 32 3.2 0 6.2-.4 8.9-1.3 19.1-5.5 46.1-10.7 74.3-3.3 57.4 14.9 124.6-7.4 174.7-57.5s72.4-117.3 57.5-174.7c-7.3-28.2-2.2-55.2 3.3-74.3.8-2.8 1.3-5.8 1.3-8.9 0-17.7-14.3-32-32-32m0-48c44.2 0 80 35.8 80 80 0 7.7-1.1 15.2-3.1 22.3-4.6 15.8-7.1 32.9-3 48.9 20.1 77.6-10.9 161.5-70 220.7s-143.1 90.2-220.7 70c-16-4.1-33-1.6-48.9 3-7.1 2-14.6 3.1-22.3 3.1-44.2 0-80-35.8-80-80 0-7.7 1.1-15.2 3.1-22.3 4.6-15.8 7.1-32.9 3-48.9-20.1-77.6 10.9-161.5 70-220.7s143.2-90.1 220.7-70c16 4.1 33 1.6 48.9-3 7.1-2 14.6-3.1 22.3-3.1M246.7 167c-52 15.2-96.5 59.7-111.7 111.7-3.7 12.7-17.1 20-29.8 16.3s-20-17-16.2-29.7c19.8-67.7 76.6-124.5 144.3-144.3 12.7-3.7 26.1 3.6 29.8 16.3s-3.6 26.1-16.3 29.8z"/></svg>

    </a>
    New Lemonade Review
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pku-lemonade/review" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pku-lemonade/review
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    README
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../hardware/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Hardware
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Hardware
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/processor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Processor Architecture
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/parallel/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Parallel and Multi-Processor Architecture
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Memory Architecture
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/accelerators/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Domain-Specific Accelerators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/network/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Interconnection Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/eda/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Electronic Design Automation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/fail/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Security and Reliability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/emerging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emerging Technologies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/perf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Performance Analysis (to be deleted)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Software
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Software
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Algorithms
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Algorithms
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#algorithm-design-and-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm design and analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Algorithm design and analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Graph Algorithms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ml-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      ML Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ML Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      Diffusion Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-regressive-models-for-image" class="md-nav__link">
    <span class="md-ellipsis">
      Auto Regressive Models for Image
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Algorithm
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Algorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Transformer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diffusion-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Diffusion LLMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Alignment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Finetune
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Finetune">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coding-llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      Coding LLM Finetune
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-powered-ai-agent" class="md-nav__link">
    <span class="md-ellipsis">
      LLM-Powered AI Agent
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      RL Algorithms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-training-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      DNN Training Algorithms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-task-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-task Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaptive-datatype" class="md-nav__link">
    <span class="md-ellipsis">
      Adaptive Datatype
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adaptive Datatype">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-llm" class="md-nav__link">
    <span class="md-ellipsis">
      For LLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm" class="md-nav__link">
    <span class="md-ellipsis">
      For Non-LLM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-method" class="md-nav__link">
    <span class="md-ellipsis">
      General method
    </span>
  </a>
  
    <nav class="md-nav" aria-label="General method">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-general-llm" class="md-nav__link">
    <span class="md-ellipsis">
      For General LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="For General LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kv-cache-specialized" class="md-nav__link">
    <span class="md-ellipsis">
      KV Cache specialized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm_1" class="md-nav__link">
    <span class="md-ellipsis">
      For Non-LLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fault-tolerance" class="md-nav__link">
    <span class="md-ellipsis">
      Fault Tolerance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-aware-training" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization-Aware Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-compression" class="md-nav__link">
    <span class="md-ellipsis">
      DNN Compression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#statistical-parameter-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Parameter Estimation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-synchronization" class="md-nav__link">
    <span class="md-ellipsis">
      Time Synchronization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#communication-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Communication Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      Data structures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data structures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Graph Processing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dynamic Graph Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture-specific-data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture-specific Data Structures
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computational-complexity" class="md-nav__link">
    <span class="md-ellipsis">
      Computational complexity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computability-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Computability theory
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Programming Languages
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../os/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Operating Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ds/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributed Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hpc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    High-Performance Computing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../perf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Performance Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#algorithm-design-and-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm design and analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Algorithm design and analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Graph Algorithms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ml-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      ML Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ML Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      Diffusion Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-regressive-models-for-image" class="md-nav__link">
    <span class="md-ellipsis">
      Auto Regressive Models for Image
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Algorithm
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Algorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Transformer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diffusion-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Diffusion LLMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Alignment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      LLM Finetune
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Finetune">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coding-llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      Coding LLM Finetune
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-powered-ai-agent" class="md-nav__link">
    <span class="md-ellipsis">
      LLM-Powered AI Agent
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      RL Algorithms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-training-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      DNN Training Algorithms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-task-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-task Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaptive-datatype" class="md-nav__link">
    <span class="md-ellipsis">
      Adaptive Datatype
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adaptive Datatype">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-llm" class="md-nav__link">
    <span class="md-ellipsis">
      For LLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm" class="md-nav__link">
    <span class="md-ellipsis">
      For Non-LLM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-method" class="md-nav__link">
    <span class="md-ellipsis">
      General method
    </span>
  </a>
  
    <nav class="md-nav" aria-label="General method">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-general-llm" class="md-nav__link">
    <span class="md-ellipsis">
      For General LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="For General LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kv-cache-specialized" class="md-nav__link">
    <span class="md-ellipsis">
      KV Cache specialized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm_1" class="md-nav__link">
    <span class="md-ellipsis">
      For Non-LLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fault-tolerance" class="md-nav__link">
    <span class="md-ellipsis">
      Fault Tolerance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-aware-training" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization-Aware Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-compression" class="md-nav__link">
    <span class="md-ellipsis">
      DNN Compression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#statistical-parameter-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Parameter Estimation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-synchronization" class="md-nav__link">
    <span class="md-ellipsis">
      Time Synchronization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#communication-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Communication Optimization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      Data structures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data structures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-processing" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Graph Processing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dynamic Graph Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture-specific-data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture-specific Data Structures
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computational-complexity" class="md-nav__link">
    <span class="md-ellipsis">
      Computational complexity
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computability-theory" class="md-nav__link">
    <span class="md-ellipsis">
      Computability theory
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/pku-lemonade/review/edit/main/docs/software/algorithm.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/pku-lemonade/review/raw/main/docs/software/algorithm.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="algorithms-theory-and-formal-methods">Algorithms, Theory, and Formal Methods<a class="headerlink" href="#algorithms-theory-and-formal-methods" title="Permanent link">&para;</a></h1>
<h2 id="algorithm-design-and-analysis">Algorithm design and analysis<a class="headerlink" href="#algorithm-design-and-analysis" title="Permanent link">&para;</a></h2>
<p>Solution: an algorithm is a well-defined, finite sequence of steps that solves a specific problem or accomplishes a particular task. We focus on algorithms that can solving problems.</p>
<h3 id="dynamic-graph-algorithms">Dynamic Graph Algorithms<a class="headerlink" href="#dynamic-graph-algorithms" title="Permanent link">&para;</a></h3>
<p>Solution: Dynamic graph algorithms efficiently update solutions to graph problems as the graph evolves, addressing the challenge of frequent changes in structure and data.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ASPLOS</td>
<td>UCR</td>
<td>CommonGraph: Graph Analytics on Evolving Data</td>
<td>convert deletions to additions; common graph concept; Triangular Grid (TG) for work sharing; mutation-free representation</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h3 id="ml-algorithms">ML Algorithms<a class="headerlink" href="#ml-algorithms" title="Permanent link">&para;</a></h3>
<p>Solution: ML algorithms are fundamental tools that enable computers to learn from data and make predictions or decisions without being explicitly programmed.</p>
<h4 id="diffusion-models">Diffusion Models<a class="headerlink" href="#diffusion-models" title="Permanent link">&para;</a></h4>
<p>Solution: Diffusion models are generative models that learn to reverse a gradual noising process to generate data from noise.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>arXiv</td>
<td>UC Berkeley</td>
<td>Scalable Diffusion Models with Transformers</td>
<td>Diffusion Transformer (DiT) architecture; replace the original U-Net with transformer blocks; adaptive layer norm (adaLN-Zero) for conditioning</td>
<td>3</td>
<td>5</td>
<td>5</td>
</tr>
</tbody>
</table>
<h4 id="auto-regressive-models-for-image">Auto Regressive Models for Image<a class="headerlink" href="#auto-regressive-models-for-image" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>NeurIPS</td>
<td>PKU</td>
<td>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</td>
<td>VAR modeling with next-scale prediction; multi-scale quantization for coarse-to-fine tokenization; power-law scaling laws for visual AR models</td>
<td>4</td>
<td>5</td>
<td>5</td>
</tr>
</tbody>
</table>
<h4 id="llm-algorithm">LLM Algorithm<a class="headerlink" href="#llm-algorithm" title="Permanent link">&para;</a></h4>
<p>Solution: enable ai chat with human, some people think is the way to AGI.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020</td>
<td>arXiv</td>
<td>OpenAI</td>
<td>Scaling Laws for Neural Language Models</td>
<td>fundamentals of LLM; increase model size and performance raise</td>
<td>4</td>
<td>5</td>
<td>5</td>
</tr>
</tbody>
</table>
<h5 id="llm-transformer">LLM Transformer<a class="headerlink" href="#llm-transformer" title="Permanent link">&para;</a></h5>
<p>Solution: Transformer is an old algorithm, which have many problems like square complexity. These problems raise new algorithms to fix the old architecture.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019</td>
<td>arXiv</td>
<td>Google</td>
<td>Fast Transformer Decoding: One Write-Head is All You Need</td>
<td>MQA; share same KV cache for all heads; multi-query attention</td>
<td>1</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>NeuroComputing</td>
<td>ZhuiYi</td>
<td>RoFormer: Enhanced Transformer with Rotary Position Embedding</td>
<td>use rotary position embedding to fix the problem of long context; nter-word dependencies decay gradually with the increase of relative distance</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Qwen</td>
<td>Parallel Scaling Law for Language Models</td>
<td>enhance model's parallel ability to enhance the performance instead of increasing the model size; parallel multi output and conclude one output</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="diffusion-llms">Diffusion LLMs<a class="headerlink" href="#diffusion-llms" title="Permanent link">&para;</a></h5>
<p>Challenge: diffusion generate result from noise, this is different from tradition's AR paradigm. Diffusion LLMs need to solve the problem of the order of text logic and the deneration of diffusion's random output index.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>Large Language Diffusion Models</td>
<td>First using diffusion LLM model to generate; Diffusion model excels at reversal reasoning; inter-block AR while in-block diffusion</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>HKU</td>
<td>Dream 7B: Diffusion Large Language Models</td>
<td>based on AR model's pre-train; inter-block diffusion</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>THU</td>
<td>Survey on Diffusion Language Models</td>
<td>survey on training strategies, inference optimization, multimodal and applications of diffusion language models</td>
<td>4</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>ByteDance</td>
<td>Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference</td>
<td>two-stage training with mask-based and edit-based noise; constrained-order training by filtering optimal generation paths; direct training to reduce generation steps</td>
<td>3</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning</td>
<td>visual instruction tuning for diffusion models; multi-stage training for multimodal reasoning; visual instruction tuning for diffusion models</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models</td>
<td>Diffusion-aware NTK extrapolation for RoPE; long-context post-training with adaptive attention masking</td>
<td>3</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="llm-alignment">LLM Alignment<a class="headerlink" href="#llm-alignment" title="Permanent link">&para;</a></h5>
<p>Solution: LLM alignment aims to make LLM outputs more consistent with user intent. Its challenges are ensuring safety, addressing multi-modal complexities, and balancing inference ability with alignment.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>SJTU</td>
<td>Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation</td>
<td>social scene simulation; emulate realistic multiparty interactions and consequences; monopolylogue</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>ICLR</td>
<td>Princeton</td>
<td>Safety Alignment Should Be Made More Than Just a Few Tokens Deep</td>
<td>ai-savety centered alignment; enhance sacety on deeper tokens and data</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>ACL</td>
<td>PKU</td>
<td>Language Models Resist Alignment: Evidence From Data Compression</td>
<td>LLM have inner resistance to alignment; the larger scale in pre-train increase the resistance</td>
<td>4</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="llm-finetune">LLM Finetune<a class="headerlink" href="#llm-finetune" title="Permanent link">&para;</a></h5>
<p>Solution: finetune adapts a pre-trained model to a specific task or domain. By doing so, the model can better fit the specific task or domain.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2021</td>
<td>ICLR</td>
<td>Miscrosoft</td>
<td>LoRA: Low-Rank Adaptation of Large Language Models</td>
<td>split the weight matrix into two parts; reduce the number of parameters to finetune</td>
<td>2</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h6 id="coding-llm-finetune">Coding LLM Finetune<a class="headerlink" href="#coding-llm-finetune" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>UMD</td>
<td>HPC-Coder-V2: Studying Code LLMs Across Low-Resource Parallel Languages</td>
<td>large synthetic parallel programming dataset; parallel code generation; HPC AI developer tools</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h6 id="llm-powered-ai-agent">LLM-Powered AI Agent<a class="headerlink" href="#llm-powered-ai-agent" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>THU</td>
<td>LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination</td>
<td>hierarchical language agent; real-time human-AI coordination; slow mind &amp; fast mind</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>THU</td>
<td>Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents</td>
<td>RAG-based LLM agent; use OpenAI api to run LLM; agent num is about 50</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Stanford</td>
<td>Generative Agent Simulations of 1000 People</td>
<td>LLM with memory system; OpenAI api to run LLM; agent num is about 1000</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>AiLab</td>
<td>OASIS: Open Agent Social Interaction Simulations with One Million Agents</td>
<td>agent simulation with large scale; run LLM on local; optimization for large scale agent simulation; agent num is about 1 million</td>
<td>4</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h4 id="rl-algorithms">RL Algorithms<a class="headerlink" href="#rl-algorithms" title="Permanent link">&para;</a></h4>
<p>Solution: RL learns from rewards or penalties received without labeled data. It takes actions that interact with the environment. It can learn optimal policies in super large config space.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2015</td>
<td>Nature</td>
<td>DeepMind</td>
<td>Human-level control through deep reinforcement learning</td>
<td>deep reinforcement learning; human-level control; playing Atari games</td>
<td>5</td>
<td>5</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>DeepReinforce</td>
<td>CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning</td>
<td>contrastive RL-driven CUDA optimization without human priors; LLM-based CUDA kernel optimization; reward design for CUDA kernel</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h4 id="dnn-training-algorithms">DNN Training Algorithms<a class="headerlink" href="#dnn-training-algorithms" title="Permanent link">&para;</a></h4>
<p>Solution: DNN training algorithms are essential for optimizing deep neural networks, enabling them to learn from data and improve their performance on various tasks. They address challenges like convergence speed, generalization, and robustness.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2017</td>
<td>ICLR</td>
<td>Stanford</td>
<td>DSD: Dense-Sparse-Dense Training for Deep Neural Networks</td>
<td>3 step dense-sparse-dense training</td>
<td>3</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>NeurIPS</td>
<td>MIT</td>
<td>Differentiable Augmentation for Data-Efficient GAN Training</td>
<td>Differentiable Augmentation to improve data efficiency in generative adversarial networks training</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>CVPR</td>
<td>NTHU</td>
<td>Robust Processing-In-Memory Neural Networks via Noise-Aware Normalization</td>
<td>noise-aware calibration in BatchNorm statistics</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>ASPLOS</td>
<td>Nvidia&amp;CMU&amp;MIT</td>
<td>GraphPipe: Improving Performance and Scalability of DNN Training with Graph Pipeline Parallelism</td>
<td>graph pipeline parallelism; topology-aware stage partitioning and scheduling algorithm</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>ZhiCun</td>
<td>Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware</td>
<td>extension of STE for complex noise environments; STE-based gradient approximation strategy</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h4 id="multi-task-learning">Multi-task Learning<a class="headerlink" href="#multi-task-learning" title="Permanent link">&para;</a></h4>
<p>Solution: Multi-task learning (MTL) is a machine learning paradigm where multiple related tasks are learned simultaneously, leveraging shared representations to improve performance across tasks.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>NeurIPS</td>
<td>Intel</td>
<td>Multi-Task Learning as Multi-Objective Optimization</td>
<td>Frank-Wolfe-based optimizer that scales to high-dimensional problems; provide an upper bound for the MGDA(multiple-gradient descent algorithm) optimization objective</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2019</td>
<td>NeurIPS</td>
<td>CUHK</td>
<td>Pareto Multi-Task Learning</td>
<td>method to decompose a MTL problem into multiple subproblems; scalable optimization algorithm to solve all constrained subproblems</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2021</td>
<td>NeurIPS</td>
<td>UTexas</td>
<td>Conflict-Averse Gradient Descent for Multi-task learning</td>
<td>Conflict-Averse Gradient descent (CAGrad); reduces the conflict among gradients while provably converges to minimum average loss</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h3 id="quantization">Quantization<a class="headerlink" href="#quantization" title="Permanent link">&para;</a></h3>
<p>Solution: Quantization are focusing on tradeoffs of accuracy and computation/memory. The challenges are how to run models in high performance and low memory/computation cost.</p>
<h4 id="adaptive-datatype">Adaptive Datatype<a class="headerlink" href="#adaptive-datatype" title="Permanent link">&para;</a></h4>
<p>Solution: Adaptive datatypes aim to optimize numerical representation by dynamically adjusting to the precision and range requirements of data. The challenge lies in balancing computational efficiency, memory usage, and accuracy across diverse tasks and hardware constraints.</p>
<h5 id="for-llm">For LLM<a class="headerlink" href="#for-llm" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ISCA</td>
<td>SJTU</td>
<td>OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization</td>
<td>outlier-victim pair that sacrifices the colocated normal values to accommodate the outliers;OVP-based quantization framework and architectural implementation</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2023</td>
<td>ICLR</td>
<td>ETH Zurich</td>
<td>GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</td>
<td>Arbitrary Order Insight; Lazy Batch-Updates； Cholesky Reformulation</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>MLSys</td>
<td>MIT</td>
<td>AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</td>
<td>Preserving 1% Salient Weights;  Protecting Salient Weights by Activation-aware Scaling; searching to scale</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Rice</td>
<td>70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float</td>
<td>dynamic-length float; preserving bit-for-bit identical outputs; BFloat16 exponents carry significantly less information than their allocated bit width</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2025</td>
<td>HPCA</td>
<td>SJTU</td>
<td>M-ANT: Efficient Low-bit Group Quantization for LLMs via Mathematically Adaptive Numerical Type</td>
<td>group-wise quantization for both weight and KV cache; new encoding paradigm to improve information utilization in group-wise quantization; specific processing element for encoding paradigm</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>HPCA</td>
<td>Cornell</td>
<td>BitMoD: Bit-serial Mixture-of-Datatype LLM Acceleration</td>
<td>introduce additional asymmetry to FP by repurposing a redundant zero value with another special value; hardware accelerator design</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="for-non-llm">For Non-LLM<a class="headerlink" href="#for-non-llm" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020</td>
<td>CVPR</td>
<td>ByteDance Inc.</td>
<td>AdaBits: Neural Network Quantization With Adaptive Bit-Widths</td>
<td>joint-quantization method applied in training;Switchable Clipping Level (SCL) between layers</td>
<td>4</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2022</td>
<td>ICLR</td>
<td>Snap Inc.</td>
<td>F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization</td>
<td>variance-based fixed-point format selection for weights and activations; training algorithm for fixed-point models</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2022</td>
<td>MICRO</td>
<td>SJTU</td>
<td>ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization</td>
<td>fixed-length adaptive numerical data type; combines the advantages of float and int for adapting to the importance of different values within a tensor; adaptive framework that selects the best type for each tensor</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>TCAD</td>
<td>HKU</td>
<td>DyBit: Dynamic Bit-Precision Numbers for Efficient Quantized Neural Network Inference</td>
<td>adaptive data representation with variablelength encoding; hardware-aware quantization framework</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>Harvard</td>
<td>Nanoscaling Floating-Point (NxFP): NanoMantissa, Adaptive Microexponents, and Code Recycling for Direct-Cast Compression of Large Language Models</td>
<td>Nanoscaling Floating-Point (NxFP); NanoMantissa; Adaptive Microexponents; Code Recycling</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>ISCA</td>
<td>SJTU</td>
<td>FATE: Boosting the Performance of Hyper-Dimensional Computing Intelligence with Flexible Numerical DAta TypE</td>
<td>dimensional fuzzing-distance importance measure; fine-grained compression framework</td>
<td>4</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<h4 id="general-method">General method<a class="headerlink" href="#general-method" title="Permanent link">&para;</a></h4>
<p>Solution: General quantization methods aim to optimize the trade-off between model accuracy and computational efficiency. Challenges include addressing layer-specific quantization errors, enhancing fault tolerance, and finding optimal bit-width configurations.</p>
<h5 id="for-general-llm">For General LLM<a class="headerlink" href="#for-general-llm" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ICML</td>
<td>MIT</td>
<td>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</td>
<td>offline migrates the quantization difficulty from activations to weights</td>
<td>4</td>
<td>5</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>ISCA</td>
<td>SNU</td>
<td>Tender: Accelerating Large Language Models via Tensor Decomposition and Runtime Requantization</td>
<td>“power of 2” channel decomposition rule; Tender accelerator design</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>PKU</td>
<td>Bitnet.cpp: Efficient Edge Inference for Ternary LLMs</td>
<td>ternary mpGEMM library; avoid intricate bit-level manipulations; achieving lossless inference for BitNet b1.58</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>AAAI</td>
<td>ByteDance</td>
<td>ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models</td>
<td>block-wise distribution correction and compensation scheme; bit balance strategy</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>ICML</td>
<td>Huawei,THU</td>
<td>FlatQuant: Flatness Matters for LLM Quantization</td>
<td>post-training quantization method to enhance the flatness of both weights and activations in LLMs</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
</tbody>
</table>
<h6 id="kv-cache-specialized">KV Cache specialized<a class="headerlink" href="#kv-cache-specialized" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>UVa</td>
<td>HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference</td>
<td>method without dequantization; homomorphic quantization method for matrix multiplication; requantization elimination</td>
<td>2</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>SJTU</td>
<td>MILLION: Mastering Long-Context LLM Inference Via Outlier-Immunized KV Product Quantization</td>
<td>a non-uniform quantization algorithm based on product quantization; leverages sparse computation and asynchronous quantization; distributes quantization power unevenly across channels</td>
<td>3</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h5 id="for-non-llm_1">For Non-LLM<a class="headerlink" href="#for-non-llm_1" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>AAAI</td>
<td>SUTD</td>
<td>Adaptive Quantization for Deep Neural Network</td>
<td>measurement to estimate the effect of parameter quantization errors in individual layers;optimization process for finding optimal quantization bit-width for each layer</td>
<td>3</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>ISCA</td>
<td>SJTU</td>
<td>DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration</td>
<td>dynamic region-based quantization algorithm; sub-feature map quantization; accelerator architecture for proposing dynamic region-based quantization</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2021</td>
<td>MLSys</td>
<td>Nvidia</td>
<td>VS-Quant: Per-vector Scaled Quantization for Accurate Low-Precision Neural Network Inference</td>
<td>per-vector(≈16-64 elements) scaled quantization technique; two-level scaling scheme and algorithm; modified MAC unit in accelerator</td>
<td>4</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>2021</td>
<td>ICML</td>
<td>Intel</td>
<td>Accurate Post Training Quantization With Small Calibration Sets</td>
<td>layer-by-layer optimization method; integer programming; para-normalization</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2023</td>
<td>ACML</td>
<td>KOBE-U</td>
<td>A Mixed-Precision Quantization Method without Accuracy Degradation Using Semilayers</td>
<td>semilayers based on whether loss difference is positive or negative</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<h5 id="fault-tolerance">Fault Tolerance<a class="headerlink" href="#fault-tolerance" title="Permanent link">&para;</a></h5>
<p>Solution: Fault tolerance in quantization ensures that models remain robust and reliable despite errors or noise</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019</td>
<td>DFT</td>
<td>Xilinx</td>
<td>Efficient Error-Tolerant Quantized Neural Network Accelerators</td>
<td>selective channel replication; fault-aware scheduling of processing elements for folded implementations</td>
<td>3</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>2023</td>
<td>DAC</td>
<td>Yonsei</td>
<td>RQ-DNN: Reliable Quantization for Fault-tolerant Deep Neural Networks</td>
<td>quantization to enhance fault tolerance caused by fault in memory; quantize to bimodal</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="quantization-aware-training">Quantization-Aware Training<a class="headerlink" href="#quantization-aware-training" title="Permanent link">&para;</a></h5>
<p>Solution: Quantization-aware training (QAT) is a technique that simulates the effects of quantization during the training process, allowing the model to learn to adapt to the quantization noise.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>arXiv</td>
<td>IBM</td>
<td>PACT: Parameterized Clipping Activation for Quantized Neural Networks</td>
<td>activation quantization scheme for finding the optimal quantization scale during training</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2020</td>
<td>ICLR</td>
<td>IBM</td>
<td>Learned Step Size Quantization</td>
<td>approximate the gradient to the quantizer step size; heuristic to bring the magnitude of step size updates into better balance with weight updates</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2022</td>
<td>CVPR</td>
<td>HKUST</td>
<td>Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation</td>
<td>Nonuniform-to-Uniform Quantizer (N2UQ) via learning input thresholds; Generalized Straight-Through Estimator (GSTE) to tackle intractable gradient computation in N2UQ</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>HKU &amp; ByteDance</td>
<td>Scaling Law for Quantization-Aware Training</td>
<td>a mathematical model for QAT quantization error</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h3 id="dnn-compression">DNN Compression<a class="headerlink" href="#dnn-compression" title="Permanent link">&para;</a></h3>
<p>Solution: DNN compression aims to reduce the size and computational requirements of deep neural networks</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2016</td>
<td>ICLR</td>
<td>Stanford</td>
<td>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</td>
<td>three stage pipeline: pruning, trained quantization and Huffman coding</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>JSTSP</td>
<td>Fraunhofer HHI</td>
<td>DeepCABAC: A Universal Compression Algorithm for Deep Neural Networks</td>
<td>identify set of priors in DNN; redefine CABAC's core scheme to capture priors</td>
<td>3</td>
<td>5</td>
<td>3</td>
</tr>
</tbody>
</table>
<h3 id="statistical-parameter-estimation">Statistical Parameter Estimation<a class="headerlink" href="#statistical-parameter-estimation" title="Permanent link">&para;</a></h3>
<p>Solution: infer the distribution of variables using statistical methods from observed data</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>1977</td>
<td>JRSSB</td>
<td>Harvard</td>
<td>Maximum Likelihood from Incomplete Data via the EM Algorithm</td>
<td>incomplete data; maximum likelihood expectation algorithm</td>
<td>2</td>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2016</td>
<td>Big Data</td>
<td>LPNU</td>
<td>Machine Learning, Linear and Bayesian Models for Logistic Regression in Failure Detection Problems</td>
<td>extreme gradient boosting classifier; generalized linear model</td>
<td>2</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>2023</td>
<td>J Process Contr</td>
<td>UA</td>
<td>Modeling and Bayesian inference for processes characterized by abrupt variations</td>
<td>dynamic latent variable model; variational Bayesian inference framework</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<h3 id="time-synchronization">Time Synchronization<a class="headerlink" href="#time-synchronization" title="Permanent link">&para;</a></h3>
<p>Solution: designing appropriate synchronization strategies, and improving the performance and adaptability of discrete event simulation</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>1993</td>
<td>JACM</td>
<td>W&amp;M</td>
<td>The Cost of Conservative Synchronization in Parallel Discrete Event Simulations</td>
<td>windowing mechanism based conservative synchronization; lower-bound performance analysis based on stochastic modeling</td>
<td>2</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2002</td>
<td>TPDS</td>
<td>Dartmouth‌</td>
<td>Composite Synchronization in Parallel Discrete-Event Simulation</td>
<td>composite synchronization mechanism; mathematical model based on synchronization overhead optimization</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2013</td>
<td>PDES</td>
<td>MSOE</td>
<td>Synchronization methods in parallel and distributed discrete-event simulation</td>
<td>conservative/optimistic synchronization methods; chandy-misra-bryant algorithm; time warp mechanism</td>
<td>3</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 id="communication-optimization">Communication Optimization<a class="headerlink" href="#communication-optimization" title="Permanent link">&para;</a></h3>
<p>Solution: modeling and searching the parameter space of collective communication libraries, dynamically selecting optimal configurations under real training/analyzing workloads</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>SIGCOMM</td>
<td>UPenn&amp;Microsoft</td>
<td>Rethinking Machine Learning Collective Communication as a Multi-Commodity Flow Problem</td>
<td>traffic engineering based collective communication optimization; mixed-integer linear program; A* technique for scaling</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>NSDI</td>
<td>USTC</td>
<td>AutoCCL: Automated Collective Communication Tuning for Accelerating Distributed and Parallel DNN Training</td>
<td>low-level performance parameters tuning; subspace division and intra-subspace coordinate descent search algorithms</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>SC</td>
<td>THU</td>
<td>TraceFlow: Efficient Trace Analysis for Large-Scale Parallel Applications via Interaction Pattern-Aware Trace Distribution</td>
<td>communication skeleton tree; interaction-aware trace distribution; communication-minimized trace shuffling</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2 id="data-structures">Data structures<a class="headerlink" href="#data-structures" title="Permanent link">&para;</a></h2>
<p>Solution: organizing and storing data efficiently to enable fast access, modification, and processing</p>
<h3 id="dynamic-graph-processing">Dynamic Graph Processing<a class="headerlink" href="#dynamic-graph-processing" title="Permanent link">&para;</a></h3>
<p>Solution: data structures for processing dynamic graphs, which are graphs that change over time.</p>
<h4 id="architecture-specific-data-structures">Architecture-specific Data Structures<a class="headerlink" href="#architecture-specific-data-structures" title="Permanent link">&para;</a></h4>
<p>Solution: Data structures targeting specific hardware architectures</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>TKDE</td>
<td>PKU</td>
<td>An Efficient Data Structure for Dynamic Graph on GPUs</td>
<td>leveled packed memory array; redundancy-free top-down re-balancing method; con-concurrent strategy Opera</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>VLDB</td>
<td>PKU</td>
<td>Towards Sufficient GPU-Accelerated Dynamic Graph Management: Survey and Experiment</td>
<td>topology structure; attribute storage; auxiliary structures</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2 id="computational-complexity">Computational complexity<a class="headerlink" href="#computational-complexity" title="Permanent link">&para;</a></h2>
<p>Solution: analyzing and classifying how the time and space requirements of an algorithm grow as the input size increases.</p>
<h2 id="computability-theory">Computability theory<a class="headerlink" href="#computability-theory" title="Permanent link">&para;</a></h2>
<p>Solution: helping to identify the fundamental limits of what can be computed, regardless of time or space constraints.</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 27, 2025 11:28:37 UTC">October 27, 2025</span>
  </span>

    
    
    
    
  </aside>


  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.indexes", "toc.follow", "navigation.top", "content.action.edit", "content.action.view", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>