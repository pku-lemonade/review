
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Youwei Zhuo">
      
      
        <link rel="canonical" href="https://review.youwei.xyz/software/algorithm/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../pl/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Algorithms - New Lemonade Review</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JXHKVQ8LKS"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JXHKVQ8LKS",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JXHKVQ8LKS",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#algorithms-theory-and-formal-methods" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="New Lemonade Review" class="md-header__button md-logo" aria-label="New Lemonade Review" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M368 80c-3.2 0-6.2.4-8.9 1.3C340 86.8 313 92 284.8 84.6c-57.4-14.9-124.6 7.4-174.7 57.5S37.7 259.4 52.6 316.8c7.3 28.2 2.2 55.2-3.3 74.3-.8 2.8-1.3 5.8-1.3 8.9 0 17.7 14.3 32 32 32 3.2 0 6.2-.4 8.9-1.3 19.1-5.5 46.1-10.7 74.3-3.3 57.4 14.9 124.6-7.4 174.7-57.5s72.4-117.3 57.5-174.7c-7.3-28.2-2.2-55.2 3.3-74.3.8-2.8 1.3-5.8 1.3-8.9 0-17.7-14.3-32-32-32m0-48c44.2 0 80 35.8 80 80 0 7.7-1.1 15.2-3.1 22.3-4.6 15.8-7.1 32.9-3 48.9 20.1 77.6-10.9 161.5-70 220.7s-143.1 90.2-220.7 70c-16-4.1-33-1.6-48.9 3-7.1 2-14.6 3.1-22.3 3.1-44.2 0-80-35.8-80-80 0-7.7 1.1-15.2 3.1-22.3 4.6-15.8 7.1-32.9 3-48.9-20.1-77.6 10.9-161.5 70-220.7s143.2-90.1 220.7-70c16 4.1 33 1.6 48.9-3 7.1-2 14.6-3.1 22.3-3.1M246.7 167c-52 15.2-96.5 59.7-111.7 111.7-3.7 12.7-17.1 20-29.8 16.3s-20-17-16.2-29.7c19.8-67.7 76.6-124.5 144.3-144.3 12.7-3.7 26.1 3.6 29.8 16.3s-3.6 26.1-16.3 29.8z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            New Lemonade Review
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Algorithms
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/pku-lemonade/review" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pku-lemonade/review
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="New Lemonade Review" class="md-nav__button md-logo" aria-label="New Lemonade Review" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M368 80c-3.2 0-6.2.4-8.9 1.3C340 86.8 313 92 284.8 84.6c-57.4-14.9-124.6 7.4-174.7 57.5S37.7 259.4 52.6 316.8c7.3 28.2 2.2 55.2-3.3 74.3-.8 2.8-1.3 5.8-1.3 8.9 0 17.7 14.3 32 32 32 3.2 0 6.2-.4 8.9-1.3 19.1-5.5 46.1-10.7 74.3-3.3 57.4 14.9 124.6-7.4 174.7-57.5s72.4-117.3 57.5-174.7c-7.3-28.2-2.2-55.2 3.3-74.3.8-2.8 1.3-5.8 1.3-8.9 0-17.7-14.3-32-32-32m0-48c44.2 0 80 35.8 80 80 0 7.7-1.1 15.2-3.1 22.3-4.6 15.8-7.1 32.9-3 48.9 20.1 77.6-10.9 161.5-70 220.7s-143.1 90.2-220.7 70c-16-4.1-33-1.6-48.9 3-7.1 2-14.6 3.1-22.3 3.1-44.2 0-80-35.8-80-80 0-7.7 1.1-15.2 3.1-22.3 4.6-15.8 7.1-32.9 3-48.9-20.1-77.6 10.9-161.5 70-220.7s143.2-90.1 220.7-70c16 4.1 33 1.6 48.9-3 7.1-2 14.6-3.1 22.3-3.1M246.7 167c-52 15.2-96.5 59.7-111.7 111.7-3.7 12.7-17.1 20-29.8 16.3s-20-17-16.2-29.7c19.8-67.7 76.6-124.5 144.3-144.3 12.7-3.7 26.1 3.6 29.8 16.3s-3.6 26.1-16.3 29.8z"/></svg>

    </a>
    New Lemonade Review
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pku-lemonade/review" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pku-lemonade/review
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    README
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../hardware/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Hardware
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Hardware
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/processor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Processor Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/parallel/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Parallel and Multi-Processor Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Memory Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/accelerators/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Domain-Specific Accelerators
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/network/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Interconnection Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/eda/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Electronic Design Automation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/fail/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Security and Reliability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/emerging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Emerging Technologies
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hardware/perf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Performance Analysis (to be deleted)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Software
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Software
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Algorithms
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Algorithms
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#algorithm-design-and-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm design and analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Algorithm design and analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Graph Algorithms
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ml-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        ML Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ML Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Diffusion Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-regressive-models-for-image" class="md-nav__link">
    <span class="md-ellipsis">
      
        Auto Regressive Models for Image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Algorithm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Algorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#speculative-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Speculative Decoding
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#early-exit-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Early Exit LLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Transformer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diffusion-llms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Diffusion LLMs
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Diffusion LLMs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dllm-with-other-technique" class="md-nav__link">
    <span class="md-ellipsis">
      
        dLLM with other technique
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Alignment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Finetune
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Finetune">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coding-llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coding LLM Finetune
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-powered-ai-agent" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM-Powered AI Agent
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM-Powered AI Agent">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-agent-for-social-simulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Agent for social simulation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-agent-for-tool-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Agent for tool use
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        RL Algorithms
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rl-parameter-adjustment" class="md-nav__link">
    <span class="md-ellipsis">
      
        RL Parameter Adjustment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-training-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        DNN Training Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DNN Training Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#differentiable-compilers-custom-ops" class="md-nav__link">
    <span class="md-ellipsis">
      
        Differentiable Compilers &amp; Custom Ops
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-task-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-task Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#graph-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      
        Graph Neural Network
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quantization
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaptive-datatype" class="md-nav__link">
    <span class="md-ellipsis">
      
        Adaptive Datatype
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adaptive Datatype">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        For LLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Non-LLM
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        General method
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="General method">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#outlier-aware-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Outlier-aware Quantization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-general-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        For General LLM
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="For General LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kv-cache-specialized" class="md-nav__link">
    <span class="md-ellipsis">
      
        KV Cache specialized
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Non-LLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fault-tolerance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fault Tolerance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-aware-training" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quantization-Aware Training
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-compression" class="md-nav__link">
    <span class="md-ellipsis">
      
        DNN Compression
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#statistical-parameter-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Statistical Parameter Estimation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-synchronization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Time Synchronization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#communication-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Communication Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fail-slow-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fail-Slow Detection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#process-variation-management" class="md-nav__link">
    <span class="md-ellipsis">
      
        Process Variation Management
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-voltage-and-frequency-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Voltage and Frequency Scaling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data structures
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data structures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-processing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Graph Processing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dynamic Graph Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture-specific-data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Architecture-specific Data Structures
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computational-complexity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computational complexity
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computability-theory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computability theory
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Programming Languages
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../os/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Operating Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ds/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Distributed Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hpc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    High-Performance Computing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../perf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Performance Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#algorithm-design-and-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm design and analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Algorithm design and analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Graph Algorithms
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ml-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        ML Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ML Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Diffusion Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-regressive-models-for-image" class="md-nav__link">
    <span class="md-ellipsis">
      
        Auto Regressive Models for Image
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Algorithm
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Algorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#speculative-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Speculative Decoding
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#early-exit-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Early Exit LLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Transformer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diffusion-llms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Diffusion LLMs
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Diffusion LLMs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dllm-with-other-technique" class="md-nav__link">
    <span class="md-ellipsis">
      
        dLLM with other technique
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Alignment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Finetune
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM Finetune">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#coding-llm-finetune" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coding LLM Finetune
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-powered-ai-agent" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM-Powered AI Agent
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LLM-Powered AI Agent">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-agent-for-social-simulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Agent for social simulation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llm-agent-for-tool-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        LLM Agent for tool use
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rl-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        RL Algorithms
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rl-parameter-adjustment" class="md-nav__link">
    <span class="md-ellipsis">
      
        RL Parameter Adjustment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-training-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        DNN Training Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DNN Training Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#differentiable-compilers-custom-ops" class="md-nav__link">
    <span class="md-ellipsis">
      
        Differentiable Compilers &amp; Custom Ops
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-task-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-task Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#graph-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      
        Graph Neural Network
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quantization
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaptive-datatype" class="md-nav__link">
    <span class="md-ellipsis">
      
        Adaptive Datatype
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Adaptive Datatype">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#for-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        For LLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Non-LLM
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        General method
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="General method">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#outlier-aware-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Outlier-aware Quantization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-general-llm" class="md-nav__link">
    <span class="md-ellipsis">
      
        For General LLM
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="For General LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kv-cache-specialized" class="md-nav__link">
    <span class="md-ellipsis">
      
        KV Cache specialized
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-non-llm_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        For Non-LLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fault-tolerance" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fault Tolerance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization-aware-training" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quantization-Aware Training
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dnn-compression" class="md-nav__link">
    <span class="md-ellipsis">
      
        DNN Compression
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#statistical-parameter-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Statistical Parameter Estimation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#time-synchronization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Time Synchronization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#communication-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Communication Optimization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fail-slow-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fail-Slow Detection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#process-variation-management" class="md-nav__link">
    <span class="md-ellipsis">
      
        Process Variation Management
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-voltage-and-frequency-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Voltage and Frequency Scaling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data structures
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data structures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dynamic-graph-processing" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dynamic Graph Processing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dynamic Graph Processing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture-specific-data-structures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Architecture-specific Data Structures
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computational-complexity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computational complexity
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computability-theory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computability theory
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/pku-lemonade/review/edit/main/docs/software/algorithm.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/pku-lemonade/review/raw/main/docs/software/algorithm.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="algorithms-theory-and-formal-methods">Algorithms, Theory, and Formal Methods<a class="headerlink" href="#algorithms-theory-and-formal-methods" title="Permanent link">&para;</a></h1>
<h2 id="algorithm-design-and-analysis">Algorithm design and analysis<a class="headerlink" href="#algorithm-design-and-analysis" title="Permanent link">&para;</a></h2>
<p>Solution: an algorithm is a well-defined, finite sequence of steps that solves a specific problem or accomplishes a particular task. We focus on algorithms that can solving problems.</p>
<h3 id="dynamic-graph-algorithms">Dynamic Graph Algorithms<a class="headerlink" href="#dynamic-graph-algorithms" title="Permanent link">&para;</a></h3>
<p>Solution: Dynamic graph algorithms efficiently update solutions to graph problems as the graph evolves, addressing the challenge of frequent changes in structure and data.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ASPLOS</td>
<td>UCR</td>
<td>CommonGraph: Graph Analytics on Evolving Data</td>
<td>convert deletions to additions; common graph concept; Triangular Grid (TG) for work sharing; mutation-free representation</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h3 id="ml-algorithms">ML Algorithms<a class="headerlink" href="#ml-algorithms" title="Permanent link">&para;</a></h3>
<p>Solution: ML algorithms are fundamental tools that enable computers to learn from data and make predictions or decisions without being explicitly programmed.</p>
<h4 id="diffusion-models">Diffusion Models<a class="headerlink" href="#diffusion-models" title="Permanent link">&para;</a></h4>
<p>Solution: Diffusion models are generative models that learn to reverse a gradual noising process to generate data from noise.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>arXiv</td>
<td>UC Berkeley</td>
<td>Scalable Diffusion Models with Transformers</td>
<td>Diffusion Transformer (DiT) architecture; replace the original U-Net with transformer blocks; adaptive layer norm (adaLN-Zero) for conditioning</td>
<td>3</td>
<td>5</td>
<td>5</td>
</tr>
</tbody>
</table>
<h4 id="auto-regressive-models-for-image">Auto Regressive Models for Image<a class="headerlink" href="#auto-regressive-models-for-image" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>NeurIPS</td>
<td>PKU</td>
<td>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</td>
<td>VAR modeling with next-scale prediction; multi-scale quantization for coarse-to-fine tokenization; power-law scaling laws for visual AR models</td>
<td>4</td>
<td>5</td>
<td>5</td>
</tr>
</tbody>
</table>
<h4 id="llm-algorithm">LLM Algorithm<a class="headerlink" href="#llm-algorithm" title="Permanent link">&para;</a></h4>
<p>Solution: enable ai chat with human, some people think is the way to AGI.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020</td>
<td>arXiv</td>
<td>OpenAI</td>
<td>Scaling Laws for Neural Language Models</td>
<td>fundamentals of LLM; increase model size and performance raise</td>
<td>4</td>
<td>5</td>
<td>5</td>
</tr>
<tr>
<td>2024</td>
<td>ICLR</td>
<td>NUS</td>
<td>Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs</td>
<td>pair-rank aggregation; verbalized confidence mimicry</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="speculative-decoding">Speculative Decoding<a class="headerlink" href="#speculative-decoding" title="Permanent link">&para;</a></h5>
<p>Solution: Speculative decoding aims to accelerate the inference of large language models (LLMs) by utilizing a smaller, faster draft model to generate multiple tokens in parallel, which are then verified and corrected by the larger, more accurate target model.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ICML</td>
<td>Google</td>
<td>Fast Inference from Transformers via Speculative Decoding</td>
<td>speculative sampling; draft/approximation model; theoretical bound of acceptance rate</td>
<td>4</td>
<td>5</td>
<td>5</td>
</tr>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>Princeton &amp; UIUC</td>
<td>Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</td>
<td>medusa heads appended to the last layer; medusa-2 joint training</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="early-exit-llm">Early Exit LLM<a class="headerlink" href="#early-exit-llm" title="Permanent link">&para;</a></h5>
<p>Solution: Early exit LLMs aim to reduce inference time and computational cost by allowing the model to produce outputs at intermediate layers when sufficient confidence is achieved.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020</td>
<td>ACL</td>
<td>UWaterloo</td>
<td>DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference</td>
<td>intermediate off-ramps; Frozen backbone fine-tuning; entropy-based inference threshold</td>
<td>3</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>ACL</td>
<td>PKU &amp; Tencent</td>
<td>FastBERT: a Self-distilling BERT with Adaptive Inference Time</td>
<td>branch-wise self-distillation; adaptive conditional computation</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="llm-transformer">LLM Transformer<a class="headerlink" href="#llm-transformer" title="Permanent link">&para;</a></h5>
<p>Solution: Transformer is an old algorithm, which have many problems like square complexity. These problems raise new algorithms to fix the old architecture.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019</td>
<td>arXiv</td>
<td>Google</td>
<td>Fast Transformer Decoding: One Write-Head is All You Need</td>
<td>MQA; share same KV cache for all heads; multi-query attention</td>
<td>1</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>NeuroComputing</td>
<td>ZhuiYi</td>
<td>RoFormer: Enhanced Transformer with Rotary Position Embedding</td>
<td>use rotary position embedding to fix the problem of long context; nter-word dependencies decay gradually with the increase of relative distance</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Qwen</td>
<td>Parallel Scaling Law for Language Models</td>
<td>enhance model's parallel ability to enhance the performance instead of increasing the model size; parallel multi output and conclude one output</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="diffusion-llms">Diffusion LLMs<a class="headerlink" href="#diffusion-llms" title="Permanent link">&para;</a></h5>
<p>Challenge: diffusion models generate result from noise, this is different from traditional AR paradigm. Diffusion LLMs need to solve the problem of the order of text logic and the generation of diffusion's random output index.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>Large Language Diffusion Models</td>
<td>First using diffusion LLM model to generate; Diffusion model excels at reversal reasoning; inter-block AR while in-block diffusion</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>HKU</td>
<td>Dream 7B: Diffusion Large Language Models</td>
<td>based on AR model's pre-train; inter-block diffusion</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>THU</td>
<td>Survey on Diffusion Language Models</td>
<td>survey on training strategies, inference optimization, multimodal and applications of diffusion language models</td>
<td>4</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>ByteDance</td>
<td>Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference</td>
<td>two-stage training with mask-based and edit-based noise; constrained-order training by filtering optimal generation paths; direct training to reduce generation steps</td>
<td>3</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models</td>
<td>Diffusion-aware NTK extrapolation for RoPE; long-context post-training with adaptive attention masking</td>
<td>3</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<h6 id="dllm-with-other-technique">dLLM with other technique<a class="headerlink" href="#dllm-with-other-technique" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning</td>
<td>visual instruction tuning for diffusion models; multi-stage training for multimodal reasoning; visual instruction tuning for diffusion models</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Nvidia</td>
<td>TiDAR: Think in Diffusion, Talk in Autoregression</td>
<td>dLLM with spec technique; use dllm-self as the draft model to accelerate the generation process</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>RUC</td>
<td>LLaDA-MoE: A Sparse MoE Diffusion Language Model</td>
<td>Sparse MoE masked diffusion architecture; variable-length training intervention; multi-stage annealing pipeline</td>
<td>4</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="llm-alignment">LLM Alignment<a class="headerlink" href="#llm-alignment" title="Permanent link">&para;</a></h5>
<p>Solution: LLM alignment aims to make LLM outputs more consistent with user intent. Its challenges are ensuring safety, addressing multi-modal complexities, and balancing inference ability with alignment.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>SJTU</td>
<td>Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation</td>
<td>social scene simulation; emulate realistic multiparty interactions and consequences; monopolylogue</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>ICLR</td>
<td>Princeton</td>
<td>Safety Alignment Should Be Made More Than Just a Few Tokens Deep</td>
<td>ai-savety centered alignment; enhance sacety on deeper tokens and data</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>ACL</td>
<td>PKU</td>
<td>Language Models Resist Alignment: Evidence From Data Compression</td>
<td>LLM have inner resistance to alignment; the larger scale in pre-train increase the resistance</td>
<td>4</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<h5 id="llm-finetune">LLM Finetune<a class="headerlink" href="#llm-finetune" title="Permanent link">&para;</a></h5>
<p>Solution: finetune adapts a pre-trained model to a specific task or domain. By doing so, the model can better fit the specific task or domain.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2021</td>
<td>ICLR</td>
<td>Miscrosoft</td>
<td>LoRA: Low-Rank Adaptation of Large Language Models</td>
<td>split the weight matrix into two parts; reduce the number of parameters to finetune</td>
<td>2</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h6 id="coding-llm-finetune">Coding LLM Finetune<a class="headerlink" href="#coding-llm-finetune" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>UMD</td>
<td>HPC-Coder-V2: Studying Code LLMs Across Low-Resource Parallel Languages</td>
<td>large synthetic parallel programming dataset; parallel code generation; HPC AI developer tools</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h5 id="llm-powered-ai-agent">LLM-Powered AI Agent<a class="headerlink" href="#llm-powered-ai-agent" title="Permanent link">&para;</a></h5>
<p>Challenge: How to scale agent number and how to reach human level behavior.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>CVPR</td>
<td>MIT</td>
<td>VirtualHome: Simulating Household Activities via Programs</td>
<td>simulation framework for home agent; interaction within the home; action planning and execution</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2023</td>
<td>ICLR</td>
<td>Google</td>
<td>ReAct: Synergizing Reasoning and Acting in Language Models</td>
<td>interleaved reasoning and acting; Thought-Act-Observation loop for LLM agents; few-shot prompting for agentic behavior</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>THU</td>
<td>LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination</td>
<td>hierarchical language agent; real-time human-AI coordination; slow mind &amp; fast mind</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>THU</td>
<td>Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents</td>
<td>RAG-based LLM agent; use OpenAI api to run LLM; agent num is about 50</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>THU</td>
<td>OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents</td>
<td>IO optimization for agent; prompt compression for LLM</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
</tbody>
</table>
<h6 id="llm-agent-for-social-simulation">LLM Agent for social simulation<a class="headerlink" href="#llm-agent-for-social-simulation" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>UIST</td>
<td>Stanford</td>
<td>Generative Agents: Interactive Simulacra of Human Behavior</td>
<td>agent socail simulation baseline; 25 agents in town</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>Fudan</td>
<td>From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents</td>
<td>dividing simulations into Individual/Scenario/Society levels; modular agent architecture analysis involving Profile-Memory-Planning-Action</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h6 id="llm-agent-for-tool-use">LLM Agent for tool use<a class="headerlink" href="#llm-agent-for-tool-use" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>NeurIPS</td>
<td>Meta</td>
<td>Toolformer: Language Models Can Teach Themselves to Use Tools</td>
<td>perplexity reduction as self-supervised signal for tool learning; automatic annotation of API calls for fine-tuning; in-context learning to generate tool-use training data</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Berkeley</td>
<td>The Berkeley Function Calling Leaderboard (BFCL): From Tool Use to Agentic Evaluation of Large Language Models</td>
<td>tool call ability benchmark</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Startup</td>
<td>MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations</td>
<td>remove unused tool in multi-turn conversation; use tool selector to select the most appropriate tool</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<h4 id="rl-algorithms">RL Algorithms<a class="headerlink" href="#rl-algorithms" title="Permanent link">&para;</a></h4>
<p>Solution: RL learns from rewards or penalties received without labeled data. It takes actions that interact with the environment. It can learn optimal policies in super large config space.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2013</td>
<td>Arxiv</td>
<td>DeepMind</td>
<td>Playing Atari with Deep Reinforcement Learning</td>
<td>Deep Q-Network (DQN) architecture; frame stacking; experience replay based random sampling</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2015</td>
<td>Nature</td>
<td>DeepMind</td>
<td>Human-level control through deep reinforcement learning</td>
<td>deep reinforcement learning; human-level control; playing Atari games</td>
<td>5</td>
<td>5</td>
<td>3</td>
</tr>
<tr>
<td>2016</td>
<td>ICLR</td>
<td>Google</td>
<td>Continuous control with Deep Reinforcement Learning</td>
<td>Deep Deterministic Policy Gradient (DDPG); soft target updates; Ornstein-Uhlenbeck (OU) action noise</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2017</td>
<td>arXiv</td>
<td>OpenAI</td>
<td>Proximal Policy Optimization Algorithms</td>
<td>clipped surrogate objective; importance sampling; Actor-Critic with shared parameters; generalized advantage estimation</td>
<td>4</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>DeepReinforce</td>
<td>CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning</td>
<td>contrastive RL-driven CUDA optimization without human priors; LLM-based CUDA kernel optimization; reward design for CUDA kernel</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h4 id="rl-parameter-adjustment">RL Parameter Adjustment<a class="headerlink" href="#rl-parameter-adjustment" title="Permanent link">&para;</a></h4>
<p>Solution: Investigate and optimize critical implementation details and hyperparameters, such as network initialization and observation normalization, to ensure training stability and maximize the agents final performance.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2015</td>
<td>Arxiv</td>
<td>Google</td>
<td>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</td>
<td>internal covariate shift; mini-batch statistics normalization; parameter scale invariance</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2020</td>
<td>ICML</td>
<td>MitsubishiElectric</td>
<td>Can Increasing Input Dimensionality Improve Deep Reinforcement Learning</td>
<td>high-dimensional feature expansion; online MLP-denseNet module; batch normalization for covariate shift</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2020</td>
<td>arXiv</td>
<td>Google</td>
<td>What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study</td>
<td>near-zero action initialization; input observation normalization; data multi-pass training</td>
<td>3</td>
<td>5</td>
<td>2</td>
</tr>
<tr>
<td>2020</td>
<td>ICLR</td>
<td>MIT</td>
<td>Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO</td>
<td>value function clipping; orthogonal initialization; trust region enforcement</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<h4 id="dnn-training-algorithms">DNN Training Algorithms<a class="headerlink" href="#dnn-training-algorithms" title="Permanent link">&para;</a></h4>
<p>Solution: DNN training algorithms are essential for optimizing deep neural networks, enabling them to learn from data and improve their performance on various tasks. They address challenges like convergence speed, generalization, and robustness.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2017</td>
<td>ICLR</td>
<td>Stanford</td>
<td>DSD: Dense-Sparse-Dense Training for Deep Neural Networks</td>
<td>3 step dense-sparse-dense training</td>
<td>3</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>NeurIPS</td>
<td>MIT</td>
<td>Differentiable Augmentation for Data-Efficient GAN Training</td>
<td>Differentiable Augmentation to improve data efficiency in generative adversarial networks training</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>CVPR</td>
<td>NTHU</td>
<td>Robust Processing-In-Memory Neural Networks via Noise-Aware Normalization</td>
<td>noise-aware calibration in BatchNorm statistics</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>ASPLOS</td>
<td>Nvidia&amp;CMU&amp;MIT</td>
<td>GraphPipe: Improving Performance and Scalability of DNN Training with Graph Pipeline Parallelism</td>
<td>graph pipeline parallelism; topology-aware stage partitioning and scheduling algorithm</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>ZhiCun</td>
<td>Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware</td>
<td>extension of STE for complex noise environments; STE-based gradient approximation strategy</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="differentiable-compilers-custom-ops">Differentiable Compilers &amp; Custom Ops<a class="headerlink" href="#differentiable-compilers-custom-ops" title="Permanent link">&para;</a></h5>
<p>Challenge: Manually deriving and implementing efficient gradients for novel operators is complex, error-prone, and hinders rapid innovation.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>SIGGRAPH</td>
<td>MIT</td>
<td>Differentiable Programming for Image Processing and Deep Learning in Halide</td>
<td>reverse-mode automatic differentiation; scatter-to-gather conversion for gradients; compiling differentiable programs</td>
<td>4</td>
<td>5</td>
<td>4</td>
</tr>
</tbody>
</table>
<h4 id="multi-task-learning">Multi-task Learning<a class="headerlink" href="#multi-task-learning" title="Permanent link">&para;</a></h4>
<p>Solution: Multi-task learning (MTL) is a machine learning paradigm where multiple related tasks are learned simultaneously, leveraging shared representations to improve performance across tasks.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>NeurIPS</td>
<td>Intel</td>
<td>Multi-Task Learning as Multi-Objective Optimization</td>
<td>Frank-Wolfe-based optimizer that scales to high-dimensional problems; provide an upper bound for the MGDA(multiple-gradient descent algorithm) optimization objective</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2019</td>
<td>NeurIPS</td>
<td>CUHK</td>
<td>Pareto Multi-Task Learning</td>
<td>method to decompose a MTL problem into multiple subproblems; scalable optimization algorithm to solve all constrained subproblems</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2021</td>
<td>NeurIPS</td>
<td>UTexas</td>
<td>Conflict-Averse Gradient Descent for Multi-task learning</td>
<td>Conflict-Averse Gradient descent (CAGrad); reduces the conflict among gradients while provably converges to minimum average loss</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h4 id="graph-neural-network">Graph Neural Network<a class="headerlink" href="#graph-neural-network" title="Permanent link">&para;</a></h4>
<p>Solution: Graph Neural Network (GNN) is a model that leverages the relationships between nodes and edges in graph-structured data to perform feature propagation and representation learning, enabling the capture of complex topological dependencies and structural patterns.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020</td>
<td>TITS</td>
<td>CSU</td>
<td>T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</td>
<td>GCN for spatial dependence; GRU for temporal dependence; noise based perturbation analysis</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2020</td>
<td>ICLR</td>
<td>Walmart</td>
<td>Inductive Representation Learning on Temporal Graphs</td>
<td>functional time encoding; temporal graph attention layer</td>
<td>3</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2020</td>
<td>AAAI</td>
<td>MIT</td>
<td>EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs</td>
<td>EvolveGCN-H / EvolveGCN-O architectures; evolving graph convolution unit; model adaptation via parameter evolution</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2023</td>
<td>ICSE</td>
<td>CUHK</td>
<td>Eadro: An End-to-End Troubleshooting Framework for Microservices on Multi-source Data</td>
<td>Hawkes process; dilated causal convolution; joint detection and localization via multi-task learning</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<h3 id="quantization">Quantization<a class="headerlink" href="#quantization" title="Permanent link">&para;</a></h3>
<p>Solution: Quantization are focusing on tradeoffs of accuracy and computation/memory. The challenges are how to run models in high performance and low memory/computation cost.</p>
<h4 id="adaptive-datatype">Adaptive Datatype<a class="headerlink" href="#adaptive-datatype" title="Permanent link">&para;</a></h4>
<p>Solution: Adaptive datatypes aim to optimize numerical representation by dynamically adjusting to the precision and range requirements of data. The challenge lies in balancing computational efficiency, memory usage, and accuracy across diverse tasks and hardware constraints.</p>
<h5 id="for-llm">For LLM<a class="headerlink" href="#for-llm" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ISCA</td>
<td>SJTU</td>
<td>OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization</td>
<td>outlier-victim pair that sacrifices the colocated normal values to accommodate the outliers;OVP-based quantization framework and architectural implementation</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2023</td>
<td>ICLR</td>
<td>ETH Zurich</td>
<td>GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</td>
<td>Arbitrary Order Insight; Lazy Batch-Updates Cholesky Reformulation</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>MLSys</td>
<td>MIT</td>
<td>AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</td>
<td>Preserving 1% Salient Weights;  Protecting Salient Weights by Activation-aware Scaling; searching to scale</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Rice</td>
<td>70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float</td>
<td>dynamic-length float; preserving bit-for-bit identical outputs; BFloat16 exponents carry significantly less information than their allocated bit width</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2025</td>
<td>HPCA</td>
<td>SJTU</td>
<td>M-ANT: Efficient Low-bit Group Quantization for LLMs via Mathematically Adaptive Numerical Type</td>
<td>group-wise quantization for both weight and KV cache; new encoding paradigm to improve information utilization in group-wise quantization; specific processing element for encoding paradigm</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>HPCA</td>
<td>Cornell</td>
<td>BitMoD: Bit-serial Mixture-of-Datatype LLM Acceleration</td>
<td>introduce additional asymmetry to FP by repurposing a redundant zero value with another special value; hardware accelerator design</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="for-non-llm">For Non-LLM<a class="headerlink" href="#for-non-llm" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020</td>
<td>CVPR</td>
<td>ByteDance Inc.</td>
<td>AdaBits: Neural Network Quantization With Adaptive Bit-Widths</td>
<td>joint-quantization method applied in training;Switchable Clipping Level (SCL) between layers</td>
<td>4</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2022</td>
<td>ICLR</td>
<td>Snap Inc.</td>
<td>F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization</td>
<td>variance-based fixed-point format selection for weights and activations; training algorithm for fixed-point models</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2022</td>
<td>MICRO</td>
<td>SJTU</td>
<td>ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization</td>
<td>fixed-length adaptive numerical data type; combines the advantages of float and int for adapting to the importance of different values within a tensor; adaptive framework that selects the best type for each tensor</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>TCAD</td>
<td>HKU</td>
<td>DyBit: Dynamic Bit-Precision Numbers for Efficient Quantized Neural Network Inference</td>
<td>adaptive data representation with variablelength encoding; hardware-aware quantization framework</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>arXiv</td>
<td>Harvard</td>
<td>Nanoscaling Floating-Point (NxFP): NanoMantissa, Adaptive Microexponents, and Code Recycling for Direct-Cast Compression of Large Language Models</td>
<td>Nanoscaling Floating-Point (NxFP); NanoMantissa; Adaptive Microexponents; Code Recycling</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>ISCA</td>
<td>SJTU</td>
<td>FATE: Boosting the Performance of Hyper-Dimensional Computing Intelligence with Flexible Numerical DAta TypE</td>
<td>dimensional fuzzing-distance importance measure; fine-grained compression framework</td>
<td>4</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<h4 id="general-method">General method<a class="headerlink" href="#general-method" title="Permanent link">&para;</a></h4>
<p>Solution: General quantization methods aim to optimize the trade-off between model accuracy and computational efficiency. Challenges include addressing layer-specific quantization errors, enhancing fault tolerance, and finding optimal bit-width configurations.</p>
<h5 id="outlier-aware-quantization">Outlier-aware Quantization<a class="headerlink" href="#outlier-aware-quantization" title="Permanent link">&para;</a></h5>
<p>Solution: Outlier-aware quantization focuses on identifying and handling outlier values in neural network</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>ICML</td>
<td>MIT</td>
<td>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</td>
<td>offline migrates the quantization difficulty from activations to weights</td>
<td>4</td>
<td>5</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>ICML</td>
<td>Huawei,THU</td>
<td>FlatQuant: Flatness Matters for LLM Quantization</td>
<td>post-training quantization method to enhance the flatness of both weights and activations in LLMs</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Houmo AI</td>
<td>ASVD: Activation-aware Singular Value Decomposition for Compressing Large Language Models</td>
<td>activation-aware scaling; sensitivity-based truncation rank searching; low-rank KV Cache storage</td>
<td>4</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>Houmo AI</td>
<td>OstQuant: Refining Large Language Model Quantization with Orthogonal and Scaling Transformations for Better Distribution Fitting</td>
<td>frobenius norm of quantization noise; iterative alternating optimization</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="for-general-llm">For General LLM<a class="headerlink" href="#for-general-llm" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>ISCA</td>
<td>SNU</td>
<td>Tender: Accelerating Large Language Models via Tensor Decomposition and Runtime Requantization</td>
<td>power of 2 channel decomposition rule; Tender accelerator design</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>PKU</td>
<td>Bitnet.cpp: Efficient Edge Inference for Ternary LLMs</td>
<td>ternary mpGEMM library; avoid intricate bit-level manipulations; achieving lossless inference for BitNet b1.58</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2025</td>
<td>AAAI</td>
<td>ByteDance</td>
<td>ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models</td>
<td>block-wise distribution correction and compensation scheme; bit balance strategy</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<h6 id="kv-cache-specialized">KV Cache specialized<a class="headerlink" href="#kv-cache-specialized" title="Permanent link">&para;</a></h6>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>UVa</td>
<td>HACK: Homomorphic Acceleration via Compression of the Key-Value Cache for Disaggregated LLM Inference</td>
<td>method without dequantization; homomorphic quantization method for matrix multiplication; requantization elimination</td>
<td>2</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>SJTU</td>
<td>MILLION: Mastering Long-Context LLM Inference Via Outlier-Immunized KV Product Quantization</td>
<td>a non-uniform quantization algorithm based on product quantization; leverages sparse computation and asynchronous quantization; distributes quantization power unevenly across channels</td>
<td>3</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h5 id="for-non-llm_1">For Non-LLM<a class="headerlink" href="#for-non-llm_1" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>AAAI</td>
<td>SUTD</td>
<td>Adaptive Quantization for Deep Neural Network</td>
<td>measurement to estimate the effect of parameter quantization errors in individual layers;optimization process for finding optimal quantization bit-width for each layer</td>
<td>3</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>ISCA</td>
<td>SJTU</td>
<td>DRQ: Dynamic Region-based Quantization for Deep Neural Network Acceleration</td>
<td>dynamic region-based quantization algorithm; sub-feature map quantization; accelerator architecture for proposing dynamic region-based quantization</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2021</td>
<td>MLSys</td>
<td>Nvidia</td>
<td>VS-Quant: Per-vector Scaled Quantization for Accurate Low-Precision Neural Network Inference</td>
<td>per-vector(16-64 elements) scaled quantization technique; two-level scaling scheme and algorithm; modified MAC unit in accelerator</td>
<td>4</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>2021</td>
<td>ICML</td>
<td>Intel</td>
<td>Accurate Post Training Quantization With Small Calibration Sets</td>
<td>layer-by-layer optimization method; integer programming; para-normalization</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2023</td>
<td>ACML</td>
<td>KOBE-U</td>
<td>A Mixed-Precision Quantization Method without Accuracy Degradation Using Semilayers</td>
<td>semilayers based on whether loss difference is positive or negative</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<h5 id="fault-tolerance">Fault Tolerance<a class="headerlink" href="#fault-tolerance" title="Permanent link">&para;</a></h5>
<p>Solution: Fault tolerance in quantization ensures that models remain robust and reliable despite errors or noise</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019</td>
<td>DFT</td>
<td>Xilinx</td>
<td>Efficient Error-Tolerant Quantized Neural Network Accelerators</td>
<td>selective channel replication; fault-aware scheduling of processing elements for folded implementations</td>
<td>3</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>2023</td>
<td>DAC</td>
<td>Yonsei</td>
<td>RQ-DNN: Reliable Quantization for Fault-tolerant Deep Neural Networks</td>
<td>quantization to enhance fault tolerance caused by fault in memory; quantize to bimodal</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
</tbody>
</table>
<h5 id="quantization-aware-training">Quantization-Aware Training<a class="headerlink" href="#quantization-aware-training" title="Permanent link">&para;</a></h5>
<p>Solution: Quantization-aware training (QAT) is a technique that simulates the effects of quantization during the training process, allowing the model to learn to adapt to the quantization noise.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018</td>
<td>arXiv</td>
<td>IBM</td>
<td>PACT: Parameterized Clipping Activation for Quantized Neural Networks</td>
<td>activation quantization scheme for finding the optimal quantization scale during training</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2020</td>
<td>ICLR</td>
<td>IBM</td>
<td>Learned Step Size Quantization</td>
<td>approximate the gradient to the quantizer step size; heuristic to bring the magnitude of step size updates into better balance with weight updates</td>
<td>3</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2022</td>
<td>CVPR</td>
<td>HKUST</td>
<td>Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation</td>
<td>Nonuniform-to-Uniform Quantizer (N2UQ) via learning input thresholds; Generalized Straight-Through Estimator (GSTE) to tackle intractable gradient computation in N2UQ</td>
<td>3</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>arXiv</td>
<td>HKU &amp; ByteDance</td>
<td>Scaling Law for Quantization-Aware Training</td>
<td>a mathematical model for QAT quantization error</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h3 id="dnn-compression">DNN Compression<a class="headerlink" href="#dnn-compression" title="Permanent link">&para;</a></h3>
<p>Solution: DNN compression aims to reduce the size and computational requirements of deep neural networks</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2016</td>
<td>ICLR</td>
<td>Stanford</td>
<td>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</td>
<td>three stage pipeline: pruning, trained quantization and Huffman coding</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
<tr>
<td>2020</td>
<td>JSTSP</td>
<td>Fraunhofer HHI</td>
<td>DeepCABAC: A Universal Compression Algorithm for Deep Neural Networks</td>
<td>identify set of priors in DNN; redefine CABAC's core scheme to capture priors</td>
<td>3</td>
<td>5</td>
<td>3</td>
</tr>
<tr>
<td>2022</td>
<td>ICLR</td>
<td>Samsung</td>
<td>Language model compression with weighted low-rank factorization</td>
<td>fisher-weighted frobenius norm; alternating least squares (ALS) for matrix factorization</td>
<td>4</td>
<td>4</td>
<td>4</td>
</tr>
</tbody>
</table>
<h3 id="statistical-parameter-estimation">Statistical Parameter Estimation<a class="headerlink" href="#statistical-parameter-estimation" title="Permanent link">&para;</a></h3>
<p>Solution: infer the distribution of variables using statistical methods from observed data</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>1977</td>
<td>JRSSB</td>
<td>Harvard</td>
<td>Maximum Likelihood from Incomplete Data via the EM Algorithm</td>
<td>incomplete data; maximum likelihood expectation algorithm</td>
<td>2</td>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2016</td>
<td>Big Data</td>
<td>LPNU</td>
<td>Machine Learning, Linear and Bayesian Models for Logistic Regression in Failure Detection Problems</td>
<td>extreme gradient boosting classifier; generalized linear model</td>
<td>2</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>2023</td>
<td>J Process Contr</td>
<td>UA</td>
<td>Modeling and Bayesian inference for processes characterized by abrupt variations</td>
<td>dynamic latent variable model; variational Bayesian inference framework</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<h3 id="time-synchronization">Time Synchronization<a class="headerlink" href="#time-synchronization" title="Permanent link">&para;</a></h3>
<p>Solution: designing appropriate synchronization strategies, and improving the performance and adaptability of discrete event simulation</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>1993</td>
<td>JACM</td>
<td>W&amp;M</td>
<td>The Cost of Conservative Synchronization in Parallel Discrete Event Simulations</td>
<td>windowing mechanism based conservative synchronization; lower-bound performance analysis based on stochastic modeling</td>
<td>2</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2002</td>
<td>TPDS</td>
<td>Dartmouth</td>
<td>Composite Synchronization in Parallel Discrete-Event Simulation</td>
<td>composite synchronization mechanism; mathematical model based on synchronization overhead optimization</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2013</td>
<td>PDES</td>
<td>MSOE</td>
<td>Synchronization methods in parallel and distributed discrete-event simulation</td>
<td>conservative/optimistic synchronization methods; chandy-misra-bryant algorithm; time warp mechanism</td>
<td>3</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 id="communication-optimization">Communication Optimization<a class="headerlink" href="#communication-optimization" title="Permanent link">&para;</a></h3>
<p>Solution: modeling and searching the parameter space of collective communication libraries, dynamically selecting optimal configurations under real training/analyzing workloads</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>SIGCOMM</td>
<td>UPenn&amp;Microsoft</td>
<td>Rethinking Machine Learning Collective Communication as a Multi-Commodity Flow Problem</td>
<td>traffic engineering based collective communication optimization; mixed-integer linear program; A* technique for scaling</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>NSDI</td>
<td>USTC</td>
<td>AutoCCL: Automated Collective Communication Tuning for Accelerating Distributed and Parallel DNN Training</td>
<td>low-level performance parameters tuning; subspace division and intra-subspace coordinate descent search algorithms</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>SC</td>
<td>THU</td>
<td>TraceFlow: Efficient Trace Analysis for Large-Scale Parallel Applications via Interaction Pattern-Aware Trace Distribution</td>
<td>communication skeleton tree; interaction-aware trace distribution; communication-minimized trace shuffling</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h3 id="fail-slow-detection">Fail-Slow Detection<a class="headerlink" href="#fail-slow-detection" title="Permanent link">&para;</a></h3>
<p>Solution: investigating how modern distributed systems detect and mitigate fail-slow behaviors, focusing on the design of detection mechanisms, threshold policies, and recovery strategies to improve system resilience under partial performance degradation</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019</td>
<td>ATC</td>
<td>UChicago</td>
<td>IASO: A Fail-Slow Detection and Mitigation Framework for Distributed Storage Services</td>
<td>slowdown detection based on peer score; sub-root causes for five kinds of root causes</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2023</td>
<td>FAST</td>
<td>SJTU &amp; Alibaba</td>
<td>PERSEUS: A Fail-Slow Detection Framework for Cloud Storage Systems</td>
<td>outlier data detection; regression model for detection threshold; risk evaluating algorithm</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2025</td>
<td>ASPDAC</td>
<td>Xiamen University</td>
<td>A Fail-Slow Detection Framework for HBM Devices</td>
<td>outlier data detection; regression model for detection threshold; risk evaluating algorithm</td>
<td>2</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2025</td>
<td>NSDI</td>
<td>SJTU &amp; UMich</td>
<td>One-Size-Fits-None: Understanding and Enhancing Slow-Fault Tolerance in Modern Distributed Systems</td>
<td>adaptive detection at runtime(ADR); slow-fault injection pipeline; danger zone analysis</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h3 id="process-variation-management">Process Variation Management<a class="headerlink" href="#process-variation-management" title="Permanent link">&para;</a></h3>
<p>Solution: Use software-level techniques to manage or exploit the on-chip heterogeneity caused by process variation; use adaptive resource allocation and workload management to improve overall performance, power efficiency, and reliability.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2014</td>
<td>DATE</td>
<td>UW-Madison</td>
<td>Process Variation-Aware Workload Partitioning Algorithms for GPUs Supporting Spatial-Multitasking</td>
<td>per-SM clocking (PSMC); process variation-aware SM-to-application assignment</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2016</td>
<td>CSUR</td>
<td>ORNL</td>
<td>A Survey of Architectural Techniques for Managing Process Variation</td>
<td>PV-aware processor management; specific component targeted management</td>
<td>3</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 id="dynamic-voltage-and-frequency-scaling">Dynamic Voltage and Frequency Scaling<a class="headerlink" href="#dynamic-voltage-and-frequency-scaling" title="Permanent link">&para;</a></h3>
<p>Solution: Develop DVFS control policies to optimize the trade-offs among performance, power consumption, and thermal constraints.</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2021</td>
<td>TCAD</td>
<td>YNU</td>
<td>CARTAD: Compiler-Assisted Reinforcement Learning for Thermal-Aware Task Scheduling and DVFS on Multicores</td>
<td>XGBoost based intrinsic feature identification; RL-Based scheduler</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2023</td>
<td>JETCAS</td>
<td>Uppsala</td>
<td>Game-of-Life Temperature-Aware DVFS Strategy for Tile-Based Chip Many-Core Processors</td>
<td>GoL temperature-aware DVFS; core/un-core performance characterizer; GoL DVFS controller</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>2024</td>
<td>ISCA</td>
<td>IBM&amp;CU</td>
<td>BlitzCoin: Fully Decentralized Hardware Power Management for Accelerator-Rich SoCs</td>
<td>coin exchange algorithm; unified voltage and frequency regulation</td>
<td>3</td>
<td>4</td>
<td>2</td>
</tr>
<tr>
<td>2024</td>
<td>DATE</td>
<td>KIT</td>
<td>Multi-Agent Reinforcement Learning for Thermally-Restricted Performance Optimization on Manycores</td>
<td>RL-based thermally-restricted performance optimization; multi-agent based per-core DVFS</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2 id="data-structures">Data structures<a class="headerlink" href="#data-structures" title="Permanent link">&para;</a></h2>
<p>Solution: organizing and storing data efficiently to enable fast access, modification, and processing</p>
<h3 id="dynamic-graph-processing">Dynamic Graph Processing<a class="headerlink" href="#dynamic-graph-processing" title="Permanent link">&para;</a></h3>
<p>Solution: data structures for processing dynamic graphs, which are graphs that change over time.</p>
<h4 id="architecture-specific-data-structures">Architecture-specific Data Structures<a class="headerlink" href="#architecture-specific-data-structures" title="Permanent link">&para;</a></h4>
<p>Solution: Data structures targeting specific hardware architectures</p>
<table>
<thead>
<tr>
<th>Year</th>
<th>Venue</th>
<th>Authors</th>
<th>Title</th>
<th>Tags</th>
<th>P</th>
<th>E</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td>TKDE</td>
<td>PKU</td>
<td>An Efficient Data Structure for Dynamic Graph on GPUs</td>
<td>leveled packed memory array; redundancy-free top-down re-balancing method; con-concurrent strategy Opera</td>
<td>4</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>2024</td>
<td>VLDB</td>
<td>PKU</td>
<td>Towards Sufficient GPU-Accelerated Dynamic Graph Management: Survey and Experiment</td>
<td>topology structure; attribute storage; auxiliary structures</td>
<td>4</td>
<td>4</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2 id="computational-complexity">Computational complexity<a class="headerlink" href="#computational-complexity" title="Permanent link">&para;</a></h2>
<p>Solution: analyzing and classifying how the time and space requirements of an algorithm grow as the input size increases.</p>
<h2 id="computability-theory">Computability theory<a class="headerlink" href="#computability-theory" title="Permanent link">&para;</a></h2>
<p>Solution: helping to identify the fundamental limits of what can be computed, regardless of time or space constraints.</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="January 21, 2026 12:55:22 UTC">January 21, 2026</span>
  </span>

    
    
    
    
  </aside>


  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.indexes", "toc.follow", "navigation.top", "content.action.edit", "content.action.view", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>